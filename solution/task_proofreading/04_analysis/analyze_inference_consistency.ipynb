{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf24e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import Levenshtein\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a91a16",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519128bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file into a list of dictionaries.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def extract_checkpoint_number(filename):\n",
    "    \"\"\"Extract checkpoint number from filename like 'predictions_checkpoint_02625.jsonl'.\"\"\"\n",
    "    match = re.search(r'checkpoint_(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "def find_highest_checkpoint(pass_dir):\n",
    "    \"\"\"Find the prediction file with the highest checkpoint number in a directory.\"\"\"\n",
    "    checkpoint_files = list(Path(pass_dir).glob('predictions_final_*.jsonl'))\n",
    "    if not checkpoint_files:\n",
    "        return None\n",
    "    \n",
    "    highest = max(checkpoint_files, key=lambda f: extract_checkpoint_number(f.name))\n",
    "    return highest\n",
    "\n",
    "def calculate_consistency_stats(pass1_data, pass2_data, pass3_data):\n",
    "    \"\"\"Calculate consistency statistics across 3 passes.\"\"\"\n",
    "    # Build dictionaries keyed by ipis_id\n",
    "    pass1_dict = {item['ipis_id']: item['target'] for item in pass1_data}\n",
    "    pass2_dict = {item['ipis_id']: item['target'] for item in pass2_data}\n",
    "    pass3_dict = {item['ipis_id']: item['target'] for item in pass3_data}\n",
    "    \n",
    "    all_match = 0\n",
    "    has_difference = 0\n",
    "    edit_distances = []\n",
    "    \n",
    "    for ipis_id in pass1_dict.keys():\n",
    "        t1 = pass1_dict[ipis_id]\n",
    "        t2 = pass2_dict[ipis_id]\n",
    "        t3 = pass3_dict[ipis_id]\n",
    "        \n",
    "        if t1 == t2 == t3:\n",
    "            all_match += 1\n",
    "        else:\n",
    "            has_difference += 1\n",
    "            # Calculate pairwise edit distances\n",
    "            d12 = Levenshtein.distance(t1, t2)\n",
    "            d13 = Levenshtein.distance(t1, t3)\n",
    "            d23 = Levenshtein.distance(t2, t3)\n",
    "            edit_distances.append(max(d12, d13, d23))\n",
    "    \n",
    "    total = len(pass1_dict)\n",
    "    determinism_rate = all_match / total * 100\n",
    "    \n",
    "    stats = {\n",
    "        'total': total,\n",
    "        'all_match': all_match,\n",
    "        'has_difference': has_difference,\n",
    "        'determinism_rate': determinism_rate,\n",
    "        'mean_edit_dist': np.mean(edit_distances) if edit_distances else 0,\n",
    "        'median_edit_dist': np.median(edit_distances) if edit_distances else 0,\n",
    "        'min_edit_dist': np.min(edit_distances) if edit_distances else 0,\n",
    "        'max_edit_dist': np.max(edit_distances) if edit_distances else 0,\n",
    "    }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c7a95c",
   "metadata": {},
   "source": [
    "## Analyze All LoRA Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "\n",
    "base_path = Path(\"solution/task_proofreading/02_inference\")\n",
    "lora_ranks = [8, 16, 32, 64, 128]\n",
    "results = defaultdict(list)\n",
    "\n",
    "output_buffer = StringIO()\n",
    "\n",
    "def write(msg):\n",
    "    \"\"\"Helper to write to buffer\"\"\"\n",
    "    output_buffer.write(msg + \"\\n\")\n",
    "\n",
    "write(\"Analyzing inference consistency across LoRA ranks...\")\n",
    "write(\"\")\n",
    "\n",
    "for rank in lora_ranks:\n",
    "    rank_dir = base_path / f\"inference_checkpoints_lora_r{rank}\"\n",
    "\n",
    "    if not rank_dir.exists():\n",
    "        write(f\"[SKIP] LoRA rank {rank}: directory not found\")\n",
    "        write(\"=\" * 100)\n",
    "        continue\n",
    "\n",
    "    write(f\"Processing LoRA rank {rank}...\")\n",
    "\n",
    "    if rank == 64:\n",
    "        pass1_file = find_highest_checkpoint(rank_dir / \"pass_1\")\n",
    "        pass2_file = find_highest_checkpoint(rank_dir / \"pass_2\")\n",
    "        pass3_file = find_highest_checkpoint(rank_dir / \"submission\")\n",
    "\n",
    "        if not all([pass1_file, pass2_file, pass3_file]):\n",
    "            write(f\"  [WARN] Missing passes for rank {rank}\")\n",
    "            write(f\"     Pass 1: {'OK' if pass1_file else 'MISSING'}\")\n",
    "            write(f\"     Pass 2: {'OK' if pass2_file else 'MISSING'}\")\n",
    "            write(f\"     Submission: {'OK' if pass3_file else 'MISSING'}\")\n",
    "            write(\"=\" * 100)\n",
    "            continue\n",
    "\n",
    "        write(f\"  Pass 1: {pass1_file.name}\")\n",
    "        write(f\"  Pass 2: {pass2_file.name}\")\n",
    "        write(f\"  Submission: {pass3_file.name}\")\n",
    "\n",
    "    elif rank == 128:\n",
    "        old_dir = rank_dir / \"OLD\"\n",
    "        if old_dir.exists():\n",
    "            write(f\"  Note: Skipping OLD folder for rank {rank}\")\n",
    "\n",
    "        pass1_file = find_highest_checkpoint(rank_dir / \"pass_1\")\n",
    "        pass2_file = find_highest_checkpoint(rank_dir / \"pass_2\")\n",
    "        pass3_file = find_highest_checkpoint(rank_dir / \"pass_3\")\n",
    "\n",
    "        if not all([pass1_file, pass2_file, pass3_file]):\n",
    "            write(f\"  [WARN] Missing passes for rank {rank}\")\n",
    "            write(f\"     Pass 1: {'OK' if pass1_file else 'MISSING'}\")\n",
    "            write(f\"     Pass 2: {'OK' if pass2_file else 'MISSING'}\")\n",
    "            write(f\"     Pass 3: {'OK' if pass3_file else 'MISSING'}\")\n",
    "            write(\"=\" * 100)\n",
    "            continue\n",
    "\n",
    "        write(f\"  Pass 1: {pass1_file.name}\")\n",
    "        write(f\"  Pass 2: {pass2_file.name}\")\n",
    "        write(f\"  Pass 3: {pass3_file.name}\")\n",
    "\n",
    "    else:\n",
    "        pass1_file = find_highest_checkpoint(rank_dir / \"pass_1\")\n",
    "        pass2_file = find_highest_checkpoint(rank_dir / \"pass_2\")\n",
    "        pass3_file = find_highest_checkpoint(rank_dir / \"pass_3\")\n",
    "\n",
    "        if not all([pass1_file, pass2_file, pass3_file]):\n",
    "            write(f\"  [WARN] Missing passes for rank {rank}\")\n",
    "            write(f\"     Pass 1: {'OK' if pass1_file else 'MISSING'}\")\n",
    "            write(f\"     Pass 2: {'OK' if pass2_file else 'MISSING'}\")\n",
    "            write(f\"     Pass 3: {'OK' if pass3_file else 'MISSING'}\")\n",
    "            write(\"=\" * 100)\n",
    "            continue\n",
    "\n",
    "        write(f\"  Pass 1: {pass1_file.name}\")\n",
    "        write(f\"  Pass 2: {pass2_file.name}\")\n",
    "        write(f\"  Pass 3: {pass3_file.name}\")\n",
    "\n",
    "    pass1_data = load_jsonl(pass1_file)\n",
    "    pass2_data = load_jsonl(pass2_file)\n",
    "    pass3_data = load_jsonl(pass3_file)\n",
    "\n",
    "    stats = calculate_consistency_stats(pass1_data, pass2_data, pass3_data)\n",
    "    stats[\"rank\"] = rank\n",
    "    results[rank].append(stats)\n",
    "\n",
    "    write(f\"  Determinism rate: {stats['determinism_rate']:.2f}%\")\n",
    "    write(f\"  Examples with differences: {stats['has_difference']}/{stats['total']}\")\n",
    "    if stats[\"has_difference\"] > 0:\n",
    "        write(f\"  Mean edit distance: {stats['mean_edit_dist']:.2f}\")\n",
    "    write(\"=\" * 100)\n",
    "\n",
    "write(\"Analysis complete!\")\n",
    "\n",
    "print(output_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1164a",
   "metadata": {},
   "source": [
    "## Aggregate Statistics by LoRA Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate stats (though each rank has only 1 data point in this case)\n",
    "aggregated_stats = {}\n",
    "\n",
    "for rank in sorted(results.keys()):\n",
    "    rank_stats = results[rank]\n",
    "    \n",
    "    if not rank_stats:\n",
    "        continue\n",
    "    \n",
    "    # Extract values\n",
    "    determinism_rates = [s['determinism_rate'] for s in rank_stats]\n",
    "    mean_edit_dists = [s['mean_edit_dist'] for s in rank_stats if s['has_difference'] > 0]\n",
    "    \n",
    "    aggregated_stats[rank] = {\n",
    "        'determinism_mean': np.mean(determinism_rates),\n",
    "        'determinism_std': np.std(determinism_rates) if len(determinism_rates) > 1 else 0,\n",
    "        'determinism_min': np.min(determinism_rates),\n",
    "        'determinism_max': np.max(determinism_rates),\n",
    "        'edit_dist_mean': np.mean(mean_edit_dists) if mean_edit_dists else 0,\n",
    "        'edit_dist_std': np.std(mean_edit_dists) if len(mean_edit_dists) > 1 else 0,\n",
    "        'edit_dist_min': np.min(mean_edit_dists) if mean_edit_dists else 0,\n",
    "        'edit_dist_max': np.max(mean_edit_dists) if mean_edit_dists else 0,\n",
    "        'total_examples': rank_stats[0]['total'],\n",
    "        'n_runs': len(rank_stats)\n",
    "    }\n",
    "\n",
    "print(\"Aggregated statistics by LoRA rank:\")\n",
    "print(\"=\"*80)\n",
    "for rank, stats in sorted(aggregated_stats.items()):\n",
    "    print(f\"\\nLoRA Rank {rank}:\")\n",
    "    print(f\"  Determinism rate: {stats['determinism_mean']:.2f}% (±{stats['determinism_std']:.2f})\")\n",
    "    print(f\"  Range: [{stats['determinism_min']:.2f}%, {stats['determinism_max']:.2f}%]\")\n",
    "    if stats['edit_dist_mean'] > 0:\n",
    "        print(f\"  Mean edit distance: {stats['edit_dist_mean']:.2f} (±{stats['edit_dist_std']:.2f})\")\n",
    "        print(f\"  Range: [{stats['edit_dist_min']:.2f}, {stats['edit_dist_max']:.2f}]\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870fb6c",
   "metadata": {},
   "source": [
    "## Generate LaTeX Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f16b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\\begin{table}[!htbp]\")\n",
    "print(\"\\\\centering\")\n",
    "print(\"\\\\small\")\n",
    "print(\"\\\\caption{Inference consistency across LoRA ranks (3 passes per rank)}\")\n",
    "print(\"\\\\label{tab:inference_consistency}\")\n",
    "print()\n",
    "print(\"\\\\begin{tabularx}{\\\\columnwidth}{Xrr}\")\n",
    "print(\"\\\\toprule\")\n",
    "print(\"\\\\textbf{LoRA Rank} & \\\\textbf{Determinism (\\\\%)\\\\textsuperscript{1}} & \\\\textbf{Mean Edit Distance\\\\textsuperscript{2}} \\\\\\\\\")\n",
    "print(\"\\\\midrule\")\n",
    "\n",
    "# Iterate through each rank\n",
    "for rank in [8, 16, 32, 64, 128]:\n",
    "    if rank in aggregated_stats:\n",
    "        det_val = f\"{aggregated_stats[rank]['determinism_mean']:.2f}\"\n",
    "        if aggregated_stats[rank]['edit_dist_mean'] > 0:\n",
    "            edit_val = f\"{aggregated_stats[rank]['edit_dist_mean']:.2f}\"\n",
    "        else:\n",
    "            edit_val = \"---\"\n",
    "    else:\n",
    "        det_val = \"---\"\n",
    "        edit_val = \"---\"\n",
    "    print(f\"r={rank} & {det_val} & {edit_val} \\\\\\\\\")\n",
    "\n",
    "print(\"\\\\bottomrule\")\n",
    "print(\"\\\\end{tabularx}\")\n",
    "print()\n",
    "print(\"\\\\vspace{2pt}\")\n",
    "print(\"\\\\raggedright\")\n",
    "print(\"\\\\footnotesize{\\\\textsuperscript{1} Percentage of examples with identical outputs across 3 inference passes (temperature=0.3)}\")\n",
    "print()\n",
    "print(\"\\\\footnotesize{\\\\textsuperscript{2} Levenshtein distance (characters) for examples with differences}\")\n",
    "print(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f9ac9",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bcb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary information\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAnalyzed LoRA ranks: {sorted(aggregated_stats.keys())}\")\n",
    "print(f\"Note: r=64 uses pass_1, pass_2, and 'submission' folder (3 passes total)\")\n",
    "print(f\"Note: r=128 uses pass_1, pass_2, pass_3 (OLD folder skipped)\")\n",
    "print(\"\\nDeterminism across ranks:\")\n",
    "for rank in sorted(aggregated_stats.keys()):\n",
    "    stats = aggregated_stats[rank]\n",
    "    print(f\"  r={rank:3d}: {stats['determinism_mean']:5.2f}% deterministic\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f2579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2395e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf6b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e923e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b381e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poleval-unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

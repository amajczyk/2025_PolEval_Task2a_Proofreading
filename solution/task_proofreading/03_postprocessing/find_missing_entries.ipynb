{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3154178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test_B entries\n",
    "test_file = Path(\"/mnt/d/Pobrane/poleval-gender/data/taskA/test_B.jsonl\")\n",
    "test_ids = []\n",
    "test_entries = {}\n",
    "\n",
    "with open(test_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:  # Skip empty lines\n",
    "            entry = json.loads(line)\n",
    "            test_ids.append(entry['ipis_id'])\n",
    "            test_entries[entry['ipis_id']] = entry\n",
    "\n",
    "print(f\"Total test entries: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prediction entries\n",
    "pred_file = Path(\"/mnt/d/Pobrane/poleval-gender/solution/task_proofreading/02_inference/predictions_test_B.jsonl\")\n",
    "pred_ids = []\n",
    "\n",
    "with open(pred_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            entry = json.loads(line)\n",
    "            pred_ids.append(entry['ipis_id'])\n",
    "\n",
    "print(f\"Total predictions: {len(pred_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66512e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids_set = set(test_ids)\n",
    "pred_ids_set = set(pred_ids)\n",
    "\n",
    "missing_ids = sorted(test_ids_set - pred_ids_set)\n",
    "\n",
    "print(f\"\\nMissing entries: {len(missing_ids)}\")\n",
    "if missing_ids:\n",
    "    print(f\"\\nMissing IDs: {missing_ids}\")\n",
    "else:\n",
    "    print(\"\\nNo missing entries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show details of missing entries\n",
    "if missing_ids:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MISSING ENTRY DETAILS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for ipis_id in missing_ids:\n",
    "        entry = test_entries[ipis_id]\n",
    "        source_text = entry['source']\n",
    "        print(f\"\\nID: {ipis_id}\")\n",
    "        print(f\"Source length: {len(source_text)} chars\")\n",
    "        print(f\"Source preview: {source_text[:200]}...\")\n",
    "        print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d499a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nChecking if IDs are in the same order...\")\n",
    "common_ids = [tid for tid in test_ids if tid in pred_ids_set]\n",
    "pred_order = [tid for tid in pred_ids if tid in test_ids_set]\n",
    "\n",
    "if common_ids == pred_order:\n",
    "    print(\"Predictions are in the same order as test file\")\n",
    "else:\n",
    "    print(\"[WARN] Predictions are in different order than test file\")\n",
    "    for i, (test_id, pred_id) in enumerate(zip(common_ids, pred_order)):\n",
    "        if test_id != pred_id:\n",
    "            print(f\"   First mismatch at position {i}: test={test_id}, pred={pred_id}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for encoding issues in the files\n",
    "import os\n",
    "\n",
    "print(\"\\nFile encoding and byte-level analysis:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check test file\n",
    "test_size = os.path.getsize(test_file)\n",
    "with open(test_file, 'rb') as f:\n",
    "    test_bytes = f.read()\n",
    "    test_newlines = test_bytes.count(b'\\n')\n",
    "\n",
    "print(f\"\\nTest file: {test_file}\")\n",
    "print(f\"  File size: {test_size} bytes\")\n",
    "print(f\"  Newline count: {test_newlines}\")\n",
    "print(f\"  Valid JSON entries: {len(test_ids)}\")\n",
    "print(f\"  Empty lines: {test_newlines - len(test_ids)}\")\n",
    "\n",
    "# Check prediction file\n",
    "pred_size = os.path.getsize(pred_file)\n",
    "with open(pred_file, 'rb') as f:\n",
    "    pred_bytes = f.read()\n",
    "    pred_newlines = pred_bytes.count(b'\\n')\n",
    "\n",
    "print(f\"\\nPrediction file: {pred_file}\")\n",
    "print(f\"  File size: {pred_size} bytes\")\n",
    "print(f\"  Newline count: {pred_newlines}\")\n",
    "print(f\"  Valid JSON entries: {len(pred_ids)}\")\n",
    "print(f\"  Empty lines: {pred_newlines - len(pred_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5de51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = Path(\"/mnt/d/Pobrane/poleval-gender/solution/task_proofreading/03_postprocessing/predictions_340_submission.tsv\")\n",
    "\n",
    "if submission_file.exists():\n",
    "    submission_ids = []\n",
    "    with open(submission_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                entry = json.loads(line)\n",
    "                submission_ids.append(entry['ipis_id'])\n",
    "    \n",
    "    print(f\"\\n\\nSubmission file analysis:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Submission file: {submission_file}\")\n",
    "    print(f\"  Valid JSON entries: {len(submission_ids)}\")\n",
    "    \n",
    "    with open(submission_file, 'rb') as f:\n",
    "        sub_bytes = f.read()\n",
    "        sub_newlines = sub_bytes.count(b'\\n')\n",
    "    \n",
    "    print(f\"  Newline count: {sub_newlines}\")\n",
    "    print(f\"  File size: {len(sub_bytes)} bytes\")\n",
    "    \n",
    "    if len(submission_ids) != len(set(submission_ids)):\n",
    "        print(f\"  [WARN] Duplicate IDs found!\")\n",
    "        from collections import Counter\n",
    "        duplicates = [id for id, count in Counter(submission_ids).items() if count > 1]\n",
    "        print(f\"  Duplicate IDs: {duplicates[:10]}\")\n",
    "    else:\n",
    "        print(f\"  No duplicate IDs\")\n",
    "    \n",
    "    sub_ids_set = set(submission_ids)\n",
    "    extra_in_sub = sub_ids_set - test_ids_set\n",
    "    if extra_in_sub:\n",
    "        print(f\"  [WARN] Extra IDs in submission not in test: {len(extra_in_sub)}\")\n",
    "        print(f\"     {sorted(list(extra_in_sub))[:5]}\")\n",
    "else:\n",
    "    print(\"\\nSubmission file not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc33025",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_check = [\n",
    "    (\"Test file\", test_file),\n",
    "    (\"Prediction file\", pred_file),\n",
    "    (\"Submission file\", submission_file)\n",
    "]\n",
    "\n",
    "print(\"Encoding and Format Analysis:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, filepath in files_to_check:\n",
    "    if filepath.exists():\n",
    "        with open(filepath, 'rb') as f:\n",
    "            raw_data = f.read()\n",
    "        \n",
    "        print(f\"\\n{name}: {filepath.name}\")\n",
    "        print(f\"  File size: {len(raw_data)} bytes\")\n",
    "        \n",
    "        if raw_data.startswith(b'\\xef\\xbb\\xbf'):\n",
    "            print(f\"  [WARN] UTF-8 BOM detected (3 bytes)\")\n",
    "        elif raw_data.startswith(b'\\xff\\xfe'):\n",
    "            print(f\"  [WARN] UTF-16 LE BOM detected\")\n",
    "        elif raw_data.startswith(b'\\xfe\\xff'):\n",
    "            print(f\"  [WARN] UTF-16 BE BOM detected\")\n",
    "        else:\n",
    "            print(f\"  No BOM\")\n",
    "        \n",
    "        crlf_count = raw_data.count(b'\\r\\n')\n",
    "        lf_only = raw_data.count(b'\\n') - crlf_count\n",
    "        cr_only = raw_data.count(b'\\r') - crlf_count\n",
    "        \n",
    "        print(f\"  Line endings:\")\n",
    "        print(f\"    - LF only (\\\\n): {lf_only}\")\n",
    "        print(f\"    - CRLF (\\\\r\\\\n): {crlf_count}\")\n",
    "        print(f\"    - CR only (\\\\r): {cr_only}\")\n",
    "        \n",
    "        if crlf_count > 0:\n",
    "            print(f\"  [WARN] Windows line endings (CRLF) detected - may cause issues!\")\n",
    "        else:\n",
    "            print(f\"  Unix line endings (LF)\")\n",
    "        \n",
    "        try:\n",
    "            text = raw_data.decode('utf-8')\n",
    "            print(f\"  Valid UTF-8 encoding\")\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"  [ERROR] UTF-8 decode error: {e}\")\n",
    "        \n",
    "        if b'\\x00' in raw_data:\n",
    "            print(f\"  [WARN] Null bytes found in file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_with_newline = Path(\"/mnt/d/Pobrane/poleval-gender/solution/task_proofreading/03_postprocessing/predictions_340_submission_v2.tsv\")\n",
    "\n",
    "with open(submission_file, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "if not content.endswith(b'\\n'):\n",
    "    print(\"[WARN] File doesn't end with newline, adding one...\")\n",
    "    with open(output_with_newline, 'wb') as f:\n",
    "        f.write(content)\n",
    "        f.write(b'\\n')\n",
    "    print(f\"Created: {output_with_newline}\")\n",
    "else:\n",
    "    print(\"File already ends with newline\")\n",
    "    output_with_newline = submission_file\n",
    "\n",
    "with open(output_with_newline, 'rb') as f:\n",
    "    new_content = f.read()\n",
    "    newline_count = new_content.count(b'\\n')\n",
    "    \n",
    "print(f\"\\nNew file stats:\")\n",
    "print(f\"  Size: {len(new_content)} bytes\")\n",
    "print(f\"  Newlines: {newline_count}\")\n",
    "print(f\"  Ends with newline: {new_content.endswith(b'\\\\n')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

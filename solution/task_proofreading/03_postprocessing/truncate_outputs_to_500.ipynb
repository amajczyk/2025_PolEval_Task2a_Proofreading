{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0a0d13",
   "metadata": {},
   "source": [
    "# Analyze Target Text Length Distribution\n",
    "\n",
    "This notebook analyzes the distribution of text lengths in the generated target texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predictions file\n",
    "predictions_file = Path(\"/mnt/d/Pobrane/poleval-gender/solution/task_proofreading/02_inference/predictions_test_B.jsonl\")\n",
    "\n",
    "# Read all entries\n",
    "entries = []\n",
    "with open(predictions_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        entries.append(json.loads(line))\n",
    "\n",
    "print(f\"Total entries: {len(entries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate token counts for target texts\n",
    "target_token_counts = []\n",
    "target_char_lengths = []\n",
    "\n",
    "for entry in entries:\n",
    "    target_text = entry.get('target', '')\n",
    "    # Count tokens\n",
    "    tokens = tokenizer.encode(target_text)\n",
    "    target_token_counts.append(len(tokens))\n",
    "    target_char_lengths.append(len(target_text))\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "df = pd.DataFrame({\n",
    "    'ipis_id': [e['ipis_id'] for e in entries],\n",
    "    'target_tokens': target_token_counts,\n",
    "    'target_chars': target_char_lengths\n",
    "})\n",
    "\n",
    "print(\"Token count statistics:\")\n",
    "print(df['target_tokens'].describe())\n",
    "print(f\"\\nEntries with target tokens > 500: {(df['target_tokens'] > 500).sum()}\")\n",
    "print(f\"Entries with target tokens > 1000: {(df['target_tokens'] > 1000).sum()}\")\n",
    "print(f\"\\nCharacter count statistics:\")\n",
    "print(df['target_chars'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram of all token lengths\n",
    "axes[0, 0].hist(df['target_tokens'], bins=50, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Target Length (tokens)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Target Text Lengths (Tokens)')\n",
    "axes[0, 0].axvline(x=500, color='red', linestyle='--', label='500 tokens', linewidth=2)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Histogram zoomed to 0-1000\n",
    "axes[0, 1].hist(df['target_tokens'], bins=50, range=(0, 1000), edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Target Length (tokens)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution (0-1000 tokens)')\n",
    "axes[0, 1].axvline(x=500, color='red', linestyle='--', label='500 tokens', linewidth=2)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1, 0].boxplot(df['target_tokens'], vert=True)\n",
    "axes[1, 0].set_ylabel('Target Length (tokens)')\n",
    "axes[1, 0].set_title('Box Plot of Target Lengths')\n",
    "axes[1, 0].axhline(y=500, color='red', linestyle='--', label='500 tokens', linewidth=2)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Cumulative distribution\n",
    "sorted_tokens = sorted(df['target_tokens'])\n",
    "cumulative = [(i+1)/len(sorted_tokens)*100 for i in range(len(sorted_tokens))]\n",
    "axes[1, 1].plot(sorted_tokens, cumulative)\n",
    "axes[1, 1].set_xlabel('Target Length (tokens)')\n",
    "axes[1, 1].set_ylabel('Cumulative Percentage (%)')\n",
    "axes[1, 1].set_title('Cumulative Distribution')\n",
    "axes[1, 1].axvline(x=500, color='red', linestyle='--', label='500 tokens', linewidth=2)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of longest targets\n",
    "print(\"Top 10 longest target texts (by token count):\\n\")\n",
    "longest = df.nlargest(10, 'target_tokens')\n",
    "for idx, row in longest.iterrows():\n",
    "    print(f\"{row['ipis_id']}: {row['target_tokens']} tokens ({row['target_chars']} chars)\")\n",
    "    print(f\"Text preview: {entries[idx]['target'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4aeab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token count distribution by ranges\n",
    "ranges = [\n",
    "    (0, 50, '0-50'),\n",
    "    (50, 100, '50-100'),\n",
    "    (100, 200, '100-200'),\n",
    "    (200, 300, '200-300'),\n",
    "    (300, 400, '300-400'),\n",
    "    (400, 500, '400-500'),\n",
    "    (500, 750, '500-750'),\n",
    "    (750, 1000, '750-1000'),\n",
    "    (1000, 2000, '1000-2000'),\n",
    "    (2000, float('inf'), '2000+')\n",
    "]\n",
    "\n",
    "print(\"\\nDistribution by token count ranges:\")\n",
    "print(\"-\" * 50)\n",
    "for start, end, label in ranges:\n",
    "    count = ((df['target_tokens'] >= start) & (df['target_tokens'] < end)).sum()\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{label:12s}: {count:4d} entries ({percentage:5.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
